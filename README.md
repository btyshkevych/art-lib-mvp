## query
Реалізований пошук у текстах [наказів МОУ](https://mod.gov.ua/diyalnist/normativno-pravova-baza/type-nakazi) та у Бойовому статуті артилерії з можливістю подачі короткого змісту з використанням LLM. На двох датасетах були застосовані різні підходи до векторизації. 
- Поділ на фрагменти тексту фіксованого розміру з накладанням (датасет - накази МОУ). У випадку конкретних словосполучень пошук показує себе добре. У випадку окремих ключових слів показує задовільні результати.
- Поділ на тематичні розділи (датасет - бойовий статут артилерії). Пошук показує себе добре. Є передумови для подальшого створення і тестування Retrieval augmented generation (RAG). Наприклад, цікавою є ідея створення сервісу на складання іспитів на знання БСА. Де LLM буде перевіряти точність відповідей.

Параметри:
```
python query.py [джерело пошуку: bsa_db або mod_orders_db] [пошуковий запис (якщо словосполучення - використати лапки)] [релевантність від 0 до 1] [кількість результатів - число 1 і більше] [додати короткий зміст від LLM - 1 або 0]
```
Пошук у бойовому статуті артилерії:
``` 
python query.py bsa_db "Бойовий наказ командира артилерійського дивізіону включає наступні розділи" 0.75 5 0
```
Пошук у наказах МОУ з підготовкою короткого змісту результату пошуку:
```
python query.py mod_orders_db "Передача квартир у комунальну власність територіальної громади" 0.75 5 1
```

Порада: обмежуйте кількість результатів під час подачі короткого змісту. Інакше запит буде виконуватися довго.

##  Що було доопрацьовано (20.11.2025):
- Накази МОУ векторизовані шляхом поділу на фрагменти (chunks) у 200 слів з накладанням (overlap) у 50 слів. Пошук повертає фрагменти тексту (чанки), a саммарі пишеться на основі усього документу. Це допомогло підвищити релевантність пошуку.
- Локальна gemma3:270m замінена клауд gpt-5-nano. Це дає швидше і якісніше саммарі документів.
- Рефакторинг фунцій пошуку тексту та видачі результатів.

##  Що було доопрацьовано (12.11.2025):
- Реалізував віртуальне середовище, щоб включити усі залежності;
- Рефакторинг, покращена структура проекту;
- Замінена модель для векторизації тексту з nomic-embed-text на lang-uk/ukr-paraphrase-multilingual-mpnet-base;
- Для самаризації тексту, llama3.2 замінена на мінімалістичну LLM gemma3:270m. Вона показує нижчу якість обробки тексту, але має вищу швидкодію, що важливіше для прототипування й усунення багів.

##  Загальні питання для подальшого удосконалення проекту:
- Покращення результатів пошуку. Необхідно доопрацювати очищення, структурування даних, попередню обробку текстів, дослідити інші методи векторизації.
- Підвищення продуктивності під час векторизації даних та роботи LLМ (можливе використання multiprocessing)
- Підбір LLМ, удосконалення промптів.
- Додати блоки try-except для керування винятками та помилками
- Документування, рефакторинг, перевикористання коду
- Безпека й адміністрування БД, бек-апи
- Доопрацювання інерфейсу у формі CLI інструменту або веб API

## Weaviate dependencies
```
docker run -p 8080:8080 -p 50051:50051 cr.weaviate.io/semitechnologies/weaviate:1.34.0
```